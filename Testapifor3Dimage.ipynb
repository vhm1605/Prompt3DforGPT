{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swFgF2zzHK9v",
        "outputId": "d6d935d5-bc03-4934-aadc-b75e69516839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.3)\n",
            "Requirement already satisfied: certifi in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2022.5.18.1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItemPawYltWM",
        "outputId": "2f705bfc-0735-4676-e26a-90ec30491fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dotenv in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.9)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dotenv) (1.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.65.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
            "Requirement already satisfied: certifi in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.5.18.1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vhm30\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EQoxHvzQln-r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vhm30\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import base64\n",
        "from openai import OpenAI, AzureOpenAI\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import dotenv\n",
        "import time\n",
        "import argparse\n",
        "import openai\n",
        "import torch\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t36xg7Z542K",
        "outputId": "944f5278-a684-47ec-9203-748cc14a9e95"
      },
      "outputs": [],
      "source": [
        "load_dotenv(dotenv_path= \"./.env\")\n",
        "\n",
        "API_KEY = os.getenv(\"OPEN_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jfdjbNqeIkeh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Thay 'your_groq_api_key_here' bằng API key thực tế của bạn\n",
        "os.environ['GROQ_API_KEY'] = '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'\n",
        "os.environ['OPENAI_API_KEY'] = API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHlQgUOtChLr",
        "outputId": "67526319-4973-412d-87f6-cac79c98f576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 200, 10, 20, 3)\n"
          ]
        }
      ],
      "source": [
        "def reshape_depth_3D(video, new_depth=200):\n",
        "  temp = torch.tensor(video).float()\n",
        "  height = temp.shape[2]\n",
        "  width = temp.shape[3]\n",
        "  temp = temp.permute(0, 4, 1, 2, 3)\n",
        "  resized_temp = torch.nn.functional.interpolate(temp, size=(new_depth, height, width), mode='trilinear', align_corners=False)\n",
        " # print(resized_temp.shape)\n",
        "  return resized_temp.permute(0, 2, 3, 4, 1).numpy()\n",
        "\n",
        "test = reshape_depth_3D(np.random.rand(1, 15, 10, 20, 3))\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XUZ2pat9zS7d"
      },
      "outputs": [],
      "source": [
        "def image_resize_for_vlm(frame, size_frame = (256, 256), inter=cv2.INTER_AREA):\n",
        "    resized_frame = cv2.resize(\n",
        "        frame, size_frame, interpolation=inter)\n",
        "    return resized_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd4JmY7IzYbi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fDWwzOwpHKCN"
      },
      "outputs": [],
      "source": [
        "# Create a grid of frames\n",
        "def create_frame_grid(video_matrix, start_indice, grid_size=5, render_pos='topright'):\n",
        "    spacer = 0\n",
        "    num_frames = grid_size**2\n",
        "    half_num_frames = num_frames // 2\n",
        "    frames = []\n",
        "    actual_indices = []\n",
        "\n",
        "\n",
        "    frames = video_matrix[start_indice:start_indice+grid_size**2]\n",
        "    actual_indices = list(range(start_indice, start_indice+grid_size**2))\n",
        "\n",
        "    if len(frames) < grid_size**2:\n",
        "        raise ValueError(\"Not enough frames to create the grid.\")\n",
        "\n",
        "    frame_height, frame_width = frames[0].shape[:2]\n",
        "\n",
        "    grid_height = grid_size * frame_height + (grid_size - 1) * spacer\n",
        "    grid_width = grid_size * frame_width + (grid_size - 1) * spacer\n",
        "\n",
        "    grid_img = np.ones((grid_height, grid_width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            index = i * grid_size + j\n",
        "            frame = frames[index]\n",
        "            cX, cY = frame.shape[1] // 2, frame.shape[0] // 2\n",
        "            max_dim = int(min(frame.shape[:2]) * 0.3)\n",
        "            overlay = frame.copy()\n",
        "            if render_pos == 'center':\n",
        "                circle_center = (cX, cY)\n",
        "            else:\n",
        "                circle_center = (frame.shape[1] - max_dim // 2, max_dim // 2)\n",
        "            cv2.circle(overlay, circle_center,\n",
        "                       max_dim // 2, (255, 255, 255), -1)\n",
        "            alpha = 0.3\n",
        "            frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
        "            cv2.circle(frame, circle_center, max_dim // 2, (255, 255, 255), 2)\n",
        "            font_scale = max_dim / 70\n",
        "            text_size = cv2.getTextSize(\n",
        "                str(index + 1), cv2.FONT_HERSHEY_SIMPLEX, font_scale, 2)[0]\n",
        "            if render_pos == 'center':\n",
        "                text_x = cX - text_size[0] // 2\n",
        "                text_y = cY + text_size[1] // 2\n",
        "            else:\n",
        "                text_x = frame.shape[1] - text_size[0] // 2 - max_dim // 2\n",
        "                text_y = text_size[1] // 2 + max_dim // 2\n",
        "            cv2.putText(frame, str(index + start_indice+1), (text_x-25, text_y),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), 5)\n",
        "            y1 = i * (frame_height + spacer)\n",
        "            y2 = y1 + frame_height\n",
        "            x1 = j * (frame_width + spacer)\n",
        "            x2 = x1 + frame_width\n",
        "            grid_img[y1:y2, x1:x2] = frame\n",
        "    return grid_img, actual_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA9ddeVRoG39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "98zEZgMFONlC"
      },
      "outputs": [],
      "source": [
        "def stack_img_understanding(stack_img, prompt_message,  size_frame = (256, 256)):\n",
        "  PROMPT_MESSAGES = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": prompt_message\n",
        "              },\n",
        "          ]\n",
        "      },\n",
        "  ]\n",
        "  total_frames = len(stack_img)\n",
        "  for i in range(total_frames):\n",
        "    frame = stack_img[i]\n",
        "    frame = image_resize_for_vlm(frame,  size_frame = size_frame)\n",
        "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
        "    base64Frame = base64.b64encode(buffer).decode(\"utf-8\")\n",
        "    my_dict = {\n",
        "        \"type\": \"image_url\",\n",
        "        \"image_url\": {\n",
        "            \"url\": f\"data:image/jpeg;base64,{base64Frame}\",\n",
        "            \"detail\": \"high\"\n",
        "        },\n",
        "    }\n",
        "    PROMPT_MESSAGES[0]['content'].append(my_dict)\n",
        "   # break\n",
        "#   client = Groq(\n",
        "#         api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        "#     )\n",
        "#   completion = client.chat.completions.create(\n",
        "#       model=\"llama-3.2-11b-vision-preview\",\n",
        "#       messages=PROMPT_MESSAGES,\n",
        "#       temperature=1,\n",
        "#       max_completion_tokens=1024,\n",
        "#       top_p=1,\n",
        "#       stream=False,\n",
        "#       stop=None,\n",
        "#   )\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
        "  completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=PROMPT_MESSAGES,\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "  return completion.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzVPhl9sqSqi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGgc3zQ9lCak"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJh_zBzYl5b2",
        "outputId": "841ff2e2-9846-41ef-85a8-bfd95af40b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content='### Báo cáo hình ảnh 3D về y tế\\n\\n#### Giới thiệu\\nBáo cáo này trình bày các hình ảnh được cắt từ hình ảnh 3D trong lĩnh vực y tế. Các hình ảnh 2D được sắp xếp theo thứ tự từ 1 đến 200 để thể hiện quá trình và chi tiết của cấu trúc được nghiên cứu.\\n\\n#### Chi tiết về hình ảnh\\n- Tất cả các hình ảnh đều được chụp dưới góc độ khác nhau, cho phép người xem có cái nhìn tổng quát và chi tiết về cấu trúc bên trong.\\n- Các số thứ tự trên hình ảnh từ 1 đến 200 thể hiện thứ tự chụp ảnh, giúp việc xác định các lớp và chi tiết dễ dàng hơn.\\n  \\n#### Phân tích\\n1. **Số lượng hình ảnh**: Tổng cộng có 200 hình ảnh, thể hiện sự cẩn trọng và chi tiết trong việc phân tích y tế.\\n2. **Hình dạng và cấu trúc**: Những hình ảnh cho thấy các cấu trúc nội bộ rõ ràng, hỗ trợ cho các bác sĩ trong việc chẩn đoán và điều trị bệnh.\\n3. **Ứng dụng**: Các hình ảnh này rất hữu ích trong lĩnh vực siêu âm, cộng hưởng từ (MRI) và các phương pháp chẩn đoán hình ảnh khác, giúp phát hiện sớm các vấn đề sức khỏe.\\n\\n#### Kết', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "def prompt_3D_image(video_path, grid_size = 5, new_depth = 200,  size_frame = (256, 256)):\n",
        "  prompt_message = (\n",
        "      f\"Viết báo cáo bằng tiếng Việt cho hình ảnh 3D về y tế sau. Tôi đã chia hình ảnh 3D thành các hình ảnh 2D, mỗi hình ảnh có một số thể hiện thứ tự của nó trong hình ảnh 3D.\"\n",
        "      \n",
        "  )\n",
        "  img_3D_array = np.load(video_path)\n",
        "\n",
        "  video_matrix = img_3D_array.reshape(1, *img_3D_array.shape, 1)\n",
        "  video_matrix = reshape_depth_3D(video_matrix, new_depth = new_depth)\n",
        "  video_matrix = video_matrix.squeeze()\n",
        " # print(video_matrix.shape)\n",
        "  if len(video_matrix.shape)==3:\n",
        "    video_matrix = np.stack([video_matrix] * 3, axis=-1)\n",
        "  #print(video_matrix.shape)\n",
        "  num_slice = grid_size**2\n",
        "  stack_img = []\n",
        "  num_grid = video_matrix.shape[0]//num_slice\n",
        "  \n",
        "  for i in range(num_grid):\n",
        "    start_indice = i * num_slice\n",
        "    image, used_frame_indices = create_frame_grid(video_matrix, start_indice, grid_size=grid_size)\n",
        "    stack_img.append(image)\n",
        "    cv2.imwrite(\n",
        "                os.path.join(\n",
        "                    '.\\Test',\n",
        "                    f\"grid_image_sample{i}.png\"),\n",
        "                image)\n",
        "  description = stack_img_understanding(stack_img, prompt_message, size_frame = size_frame)\n",
        "  print(description)\n",
        "  return description\n",
        "\n",
        "prompt_3D_image('.\\ct.npy')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
